{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e48c58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.spectra_encoder import SpectraEncoder, SpectraEncoderGrowing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0461ce",
   "metadata": {},
   "source": [
    "# Test forward run of SpectraEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7c01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize the model with required parameters\n",
    "model = SpectraEncoder(\n",
    "    form_embedder=\"float\",\n",
    "    output_size=4096,\n",
    "    hidden_size=256,  # Using a reasonable size for testing\n",
    "    spectra_dropout=0.1,\n",
    "    top_layers=2,\n",
    "    refine_layers=0,\n",
    "    magma_modulo=2048,\n",
    "    peak_attn_layers=4,  # Important parameter for FormulaTransformer\n",
    "    num_heads=8,\n",
    "    set_pooling=\"intensity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8badf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85781/3023852962.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  'magma_fps': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "spec_features = {'peak_type': array([0, 0, 0, 0, 0, 0, 0, 0, 3]),\n",
    " 'form_vec': array([[ 6.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          3.,  0.,  0.,  0.,  0.],\n",
    "        [14., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "          3.,  0.,  0.,  0.,  0.],\n",
    "        [ 7.,  8.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "          3.,  0.,  0.,  0.,  0.],\n",
    "        [13., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          1.,  0.,  0.,  0.,  0.],\n",
    "        [ 7.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.],\n",
    "        [14., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          3.,  0.,  0.,  0.,  0.],\n",
    "        [ 7.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "          3.,  0.,  0.,  0.,  0.],\n",
    "        [13., 13.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "          1.,  0.,  0.,  0.,  0.],\n",
    "        [16., 17.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "          4.,  0.,  0.,  0.,  0.]]),\n",
    " 'ion_vec': [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    " 'frag_intens': array([1.        , 0.85716669, 0.5961169 , 0.59105782, 0.49522242,\n",
    "        0.37701743, 0.28298424, 0.21223818, 1.        ]),\n",
    " 'name': 'MassSpecGymID0000001',\n",
    " 'magma_fps': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
    "        ...,\n",
    "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
    "        [-1., -1., -1., ..., -1., -1., -1.]]),\n",
    " 'magma_aux_loss': True,\n",
    " 'instrument': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62809b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the spec_features dictionary to a batch format (adding batch dimension)\n",
    "def prepare_batch(spec_features):\n",
    "    batch = {}\n",
    "    # Number of peaks\n",
    "    num_peaks = len(spec_features['peak_type'])\n",
    "    batch['num_peaks'] = torch.tensor([num_peaks], dtype=torch.long)\n",
    "    \n",
    "    # Peak types\n",
    "    batch['types'] = torch.tensor(spec_features['peak_type'], dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    # Formula vectors\n",
    "    batch['form_vec'] = torch.tensor(spec_features['form_vec'], dtype=torch.float).unsqueeze(0)\n",
    "    \n",
    "    # Ion vectors\n",
    "    batch['ion_vec'] = torch.tensor(spec_features['ion_vec'], dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    # Intensity values\n",
    "    batch['intens'] = torch.tensor(spec_features['frag_intens'], dtype=torch.float).unsqueeze(0)\n",
    "    \n",
    "    # Instrument\n",
    "    batch['instruments'] = torch.tensor([spec_features['instrument']], dtype=torch.long)\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Prepare the batcha\n",
    "batch = prepare_batch(spec_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cde66db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_peaks': tensor([9]),\n",
       " 'types': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 3]]),\n",
       " 'form_vec': tensor([[[ 6.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,\n",
       "            0.,  0.,  0.,  0.],\n",
       "          [14., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  3.,\n",
       "            0.,  0.,  0.,  0.],\n",
       "          [ 7.,  8.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  3.,\n",
       "            0.,  0.,  0.,  0.],\n",
       "          [13., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "            0.,  0.,  0.,  0.],\n",
       "          [ 7.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "            0.,  0.,  0.,  0.],\n",
       "          [14., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,\n",
       "            0.,  0.,  0.,  0.],\n",
       "          [ 7.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  3.,\n",
       "            0.,  0.,  0.,  0.],\n",
       "          [13., 13.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "            0.,  0.,  0.,  0.],\n",
       "          [16., 17.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  4.,\n",
       "            0.,  0.,  0.,  0.]]]),\n",
       " 'ion_vec': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'intens': tensor([[1.0000, 0.8572, 0.5961, 0.5911, 0.4952, 0.3770, 0.2830, 0.2122, 1.0000]]),\n",
       " 'instruments': tensor([0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b110d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 4096])\n",
      "Predicted fragment fingerprints shape: torch.Size([1, 9, 2048])\n",
      "Hidden state shape: torch.Size([1, 256])\n",
      "Output min/max: 0.2793/0.7018\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Run forward pass\n",
    "with torch.no_grad():\n",
    "    output, aux_outputs = model(batch)\n",
    "    \n",
    "# Print shapes to verify\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Predicted fragment fingerprints shape: {aux_outputs['pred_frag_fps'].shape}\")\n",
    "print(f\"Hidden state shape: {aux_outputs['h0'].shape}\")\n",
    "\n",
    "# Check values\n",
    "print(f\"Output min/max: {output.min().item():.4f}/{output.max().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b883c",
   "metadata": {},
   "source": [
    "# Test forward run of SpectraEncoderGrowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ea6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SpectraEncoderGrowing(\n",
    "    form_embedder=\"float\",\n",
    "    output_size=4096,\n",
    "    hidden_size=256,\n",
    "    spectra_dropout=0.1,\n",
    "    top_layers=2,\n",
    "    refine_layers=3,  # Number of splits in FPGrowingModule\n",
    "    magma_modulo=2048,\n",
    "    peak_attn_layers=4,\n",
    "    num_heads=8,\n",
    "    set_pooling=\"intensity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ec66439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 4096])\n",
      "Predicted fragment fingerprints shape: torch.Size([1, 9, 2048])\n",
      "Hidden state shape: torch.Size([1, 256])\n",
      "Intermediate prediction 0 shape: torch.Size([1, 512])\n",
      "Intermediate prediction 1 shape: torch.Size([1, 1024])\n",
      "Intermediate prediction 2 shape: torch.Size([1, 2048])\n",
      "Output min/max: 0.0496/0.4883\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model2.eval()\n",
    "\n",
    "# Run forward pass\n",
    "with torch.no_grad():\n",
    "    output, aux_outputs = model2(batch)\n",
    "    \n",
    "# Print shapes to verify\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Predicted fragment fingerprints shape: {aux_outputs['pred_frag_fps'].shape}\")\n",
    "print(f\"Hidden state shape: {aux_outputs['h0'].shape}\")\n",
    "\n",
    "# Check intermediate predictions (specific to SpectraEncoderGrowing)\n",
    "for i, intermediate in enumerate(aux_outputs[\"int_preds\"]):\n",
    "    print(f\"Intermediate prediction {i} shape: {intermediate.shape}\")\n",
    "\n",
    "# Check values\n",
    "print(f\"Output min/max: {output.min().item():.4f}/{output.max().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Initialize your model first (with the same parameters as the saved model)\n",
    "model = SpectraEncoderGrowing(\n",
    "    form_embedder=\"float\",\n",
    "    output_size=4096,\n",
    "    hidden_size=256,\n",
    "    spectra_dropout=0.1,\n",
    "    top_layers=2,\n",
    "    refine_layers=3,\n",
    "    magma_modulo=2048,\n",
    "    peak_attn_layers=4,\n",
    "    num_heads=8,\n",
    "    set_pooling=\"intensity\"\n",
    ")\n",
    "\n",
    "# Path to the checkpoint\n",
    "checkpoint_path = \"services/DiffMS/checkpoints/model_checkpoints/encoder_msg.pt\"\n",
    "\n",
    "# Check if the checkpoint exists\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "else:\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    \n",
    "    # Check the contents of the checkpoint\n",
    "    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "        # Case: Checkpoint is a dictionary with 'state_dict' key\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        # Case: Checkpoint is directly the state_dict\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    # Print some information about the loaded state_dict\n",
    "    print(f\"Loaded checkpoint with {len(state_dict)} keys\")\n",
    "    \n",
    "    # Try to load the weights into the model\n",
    "    try:\n",
    "        # Check if we need to remove prefixes from state_dict keys\n",
    "        if any(key.startswith('module.') for key in state_dict):\n",
    "            # Remove 'module.' prefix (common when model was trained with DataParallel)\n",
    "            state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Load state dictionary\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(\"Model weights loaded successfully!\")\n",
    "        \n",
    "        # If you want to see which parameters were loaded and which were not\n",
    "        model_dict = model.state_dict()\n",
    "        missing_keys = [key for key in model_dict if key not in state_dict]\n",
    "        unexpected_keys = [key for key in state_dict if key not in model_dict]\n",
    "        \n",
    "        if missing_keys:\n",
    "            print(f\"Warning: {len(missing_keys)} keys in model were not found in checkpoint:\")\n",
    "            print(missing_keys[:5], \"...\" if len(missing_keys) > 5 else \"\")\n",
    "        \n",
    "        if unexpected_keys:\n",
    "            print(f\"Warning: {len(unexpected_keys)} keys in checkpoint were not used:\")\n",
    "            print(unexpected_keys[:5], \"...\" if len(unexpected_keys) > 5 else \"\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights: {e}\")\n",
    "\n",
    "# Model is now loaded and ready for inference\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f02a4",
   "metadata": {},
   "source": [
    "# Load the checkpoint weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1624008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Initialize your model first (with the same parameters as the saved model)\n",
    "model = SpectraEncoderGrowing(\n",
    "                        inten_transform='float',\n",
    "                        inten_prob=0.1,\n",
    "                        remove_prob=0.5,\n",
    "                        peak_attn_layers=2,\n",
    "                        num_heads=8,\n",
    "                        pairwise_featurization=True,\n",
    "                        embed_instrument=False,\n",
    "                        cls_type='ms1',\n",
    "                        set_pooling='cls',\n",
    "                        spec_features='peakformula',\n",
    "                        mol_features='fingerprint',\n",
    "                        form_embedder='pos-cos',\n",
    "                        output_size=4096,\n",
    "                        hidden_size=512,\n",
    "                        spectra_dropout=0.1,\n",
    "                        top_layers=1,\n",
    "                        refine_layers=4,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a2bb788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint with 59 keys\n"
     ]
    }
   ],
   "source": [
    "# Path to the checkpoint\n",
    "checkpoint_path = \"/home/i_golov/Spectrum_Structure_prediction/Spectrum-to-Molecular/services/DiffMS/checkpoints/model_checkpoints/encoder_msg.pt\"\n",
    "\n",
    "# Check if the checkpoint exists\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "else:\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    # Check the contents of the checkpoint\n",
    "    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "        # Case: Checkpoint is a dictionary with 'state_dict' key\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        # Case: Checkpoint is directly the state_dict\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "# Print some information about the loaded state_dict\n",
    "print(f\"Loaded checkpoint with {len(state_dict)} keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cc3d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpectraEncoderGrowing(\n",
       "  (spectra_encoder): ModuleList(\n",
       "    (0): FormulaTransformer(\n",
       "      (form_embedder_mod): FourierFeaturizerPosCos()\n",
       "      (intermediate_layer): MLPBlocks(\n",
       "        (activation): ReLU()\n",
       "        (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "        (input_layer): Linear(in_features=343, out_features=512, bias=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (pairwise_featurizer): MLPBlocks(\n",
       "        (activation): ReLU()\n",
       "        (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "        (input_layer): Linear(in_features=162, out_features=512, bias=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (peak_attn_layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    )\n",
       "    (2): FPGrowingModule(\n",
       "      (initial_predict): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "      (predict_bricks): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (gate_bricks): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to load the weights into the model\n",
    "try:\n",
    "    # Check if we need to remove prefixes from state_dict keys\n",
    "    if any(key.startswith('module.') for key in state_dict):\n",
    "        # Remove 'module.' prefix (common when model was trained with DataParallel)\n",
    "        state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}\n",
    "    \n",
    "    # Load state dictionary\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    print(\"Model weights loaded successfully!\")\n",
    "    \n",
    "    # If you want to see which parameters were loaded and which were not\n",
    "    model_dict = model.state_dict()\n",
    "    missing_keys = [key for key in model_dict if key not in state_dict]\n",
    "    unexpected_keys = [key for key in state_dict if key not in model_dict]\n",
    "    \n",
    "    if missing_keys:\n",
    "        print(f\"Warning: {len(missing_keys)} keys in model were not found in checkpoint:\")\n",
    "        print(missing_keys[:5], \"...\" if len(missing_keys) > 5 else \"\")\n",
    "    \n",
    "    if unexpected_keys:\n",
    "        print(f\"Warning: {len(unexpected_keys)} keys in checkpoint were not used:\")\n",
    "        print(unexpected_keys[:5], \"...\" if len(unexpected_keys) > 5 else \"\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading weights: {e}\")\n",
    "\n",
    "# Model is now loaded and ready for inference\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba8ea07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output, aux_outputs = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4795c72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pred_frag_fps', 'int_preds', 'h0'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_outputs.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectrum-to-molecular-ECHCqm5f-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
