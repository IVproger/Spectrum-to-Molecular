{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f250e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9067a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i_golov/.cache/pypoetry/virtualenvs/spectrum-to-molecular-ECHCqm5f-py3.10/lib/python3.10/site-packages/torch_geometric/utils/convert.py:4: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  import scipy.sparse\n"
     ]
    }
   ],
   "source": [
    "from processors.processors_diffms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500608a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "\n",
    "def smiles_to_fingerprint(smiles: str, n_bits: int, radius: int) -> np.ndarray:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None: \n",
    "                print(\"Molecula formula not defined\")\n",
    "                return np.zeros(n_bits, dtype=np.float32)\n",
    "        mfpgen = rdFingerprintGenerator.GetMorganGenerator(fpSize=n_bits, radius=radius)\n",
    "        fp = mfpgen.GetFingerprint(mol)\n",
    "        return np.array(fp, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d2bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the spec_features dictionary to a batch format (adding batch dimension)\n",
    "def prepare_features(spec_features_dict):\n",
    "    \"\"\"Converts features from numpy arrays to PyTorch tensors.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    features['num_peaks'] = len(spec_features_dict['peak_type'])\n",
    "    \n",
    "    # Convert arrays to tensors\n",
    "    features['types'] = torch.tensor(spec_features_dict['peak_type'], dtype=torch.long)\n",
    "    features['form_vec'] = torch.tensor(spec_features_dict['form_vec'], dtype=torch.float)\n",
    "    features['ion_vec'] = torch.tensor(spec_features_dict['ion_vec'], dtype=torch.long)\n",
    "    features['intens'] = torch.tensor(spec_features_dict['frag_intens'], dtype=torch.float)\n",
    "    features['instruments'] = torch.tensor(spec_features_dict['instrument'], dtype=torch.long) \n",
    "    features['num_peaks'] = torch.tensor(features['num_peaks'] , dtype=torch.long) \n",
    "    \n",
    "    if 'magma_fps' in spec_features_dict:\n",
    "         # Ensure magma_fps is float for consistency, handle -1 if needed\n",
    "         magma_fps_np = spec_features_dict['magma_fps']\n",
    "         features['magma_fps'] = torch.tensor(magma_fps_np, dtype=torch.float)\n",
    "         features['magma_aux_loss'] = spec_features_dict['magma_aux_loss']\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d74abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def spectra_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collates a list of dictionaries from SpectraDataset into a padded batch.\n",
    "\n",
    "    Args:\n",
    "        batch (list): A list of dictionaries, where each dict is an output\n",
    "                      from SpectraDataset.__getitem__.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing batched and padded tensors,\n",
    "              or None if the batch is empty after filtering.\n",
    "    \"\"\"\n",
    "    # Filter out None items resulting from errors in __getitem__\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    \n",
    "    target_fps = torch.stack([item['target_fp'] for item in batch], dim=0)\n",
    "    instruments = torch.stack([item['instruments'] for item in batch], dim=0)\n",
    "    \n",
    "    # --- Handle sequence padding ---\n",
    "    # Get sequence lengths (num_peaks) - from python ints\n",
    "    num_peaks = torch.tensor([item['num_peaks'] for item in batch], dtype=torch.long)\n",
    "    max_len = num_peaks.max().item() if len(num_peaks) > 0 else 0 # Handle empty batch case\n",
    "    \n",
    "    # Prepare lists of tensors for pad_sequence\n",
    "    types_list = [item['types'] for item in batch]\n",
    "    form_vec_list = [item['form_vec'] for item in batch]\n",
    "    ion_vec_list = [item['ion_vec'] for item in batch]\n",
    "    intens_list = [item['intens'] for item in batch]\n",
    "    \n",
    "    # Pad sequences: batch_first=True gives [batch_size, max_len, ...]\n",
    "    # Use 0 for padding value, adjust if a different value is semantically better\n",
    "    batched_types = pad_sequence(types_list, batch_first=True, padding_value=0)\n",
    "    batched_form_vecs = pad_sequence(form_vec_list, batch_first=True, padding_value=0.0)\n",
    "    batched_ion_vecs = pad_sequence(ion_vec_list, batch_first=True, padding_value=0)\n",
    "    batched_intens = pad_sequence(intens_list, batch_first=True, padding_value=0.0)\n",
    "    \n",
    "    mask = torch.arange(max_len)[None, :] < num_peaks[:, None]\n",
    "    \n",
    "    final_batch = {\n",
    "        'target_fp': target_fps,\n",
    "        'instruments': instruments,\n",
    "        'num_peaks': num_peaks,\n",
    "        'types': batched_types,\n",
    "        'form_vec': batched_form_vecs,\n",
    "        'ion_vec': batched_ion_vecs,\n",
    "        'intens': batched_intens,\n",
    "        'mask': mask\n",
    "    }\n",
    "    \n",
    "    if 'magma_fps' in batch[0]:\n",
    "        magma_fps_list = [item['magma_fps'] for item in batch]\n",
    "        # Pad MAGMA fingerprints. Using 0.0 as padding value.\n",
    "        # The original data uses -1 for missing FPs, padding adds 0s.\n",
    "        # Ensure your model handles both -1 (missing) and 0 (padding or inactive bit) appropriately.\n",
    "        batched_magma_fps = pad_sequence(magma_fps_list, batch_first=True, padding_value=0.0)\n",
    "        final_batch['magma_fps'] = batched_magma_fps\n",
    "        # Carry over the boolean flag (assuming it's the same for the whole batch)\n",
    "        final_batch['magma_aux_loss'] = batch[0]['magma_aux_loss']\n",
    "        \n",
    "    return final_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4850b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectraDataset(Dataset):\n",
    "    \"\"\"Dataset for loading spectra and SMILES from a CSV file.\"\"\"\n",
    "    def __init__(self, data_file_path, spectrum_processor, target_fp_size, is_train=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_file_path (str): Path to the CSV file.\n",
    "            spectrum_processor (SpectrumProcessor): Instance to process spectra.\n",
    "            target_fp_size (int): The desired size of the target fingerprint.\n",
    "            is_train (bool): Flag indicating if this is for training (enables augmentation).\n",
    "        \"\"\"\n",
    "        self.processor = spectrum_processor\n",
    "        self.target_fp_size = target_fp_size\n",
    "        self.is_train = is_train\n",
    "        self.morgan_radius = 2\n",
    "        \n",
    "        try:\n",
    "            self.data = pd.read_csv(data_file_path)\n",
    "            \n",
    "            # Validate required columns\n",
    "            required_cols = ['spec', 'smiles', 'extracted_spectral_info']\n",
    "            if not all(col in self.data.columns for col in required_cols):\n",
    "                raise ValueError(f\"CSV must contain columns: {required_cols}\")\n",
    "            print(f\"Loaded {len(self.data)} records from {data_file_path}\")\n",
    "            \n",
    "            # TODO implement the SMILES validation and filtering\n",
    "            # Optional: Pre-filter invalid SMILES to avoid errors during training\n",
    "            # self.data['valid_smiles'] = self.data['smiles'].apply(lambda x: Chem.MolFromSmiles(str(x)) is not None)\n",
    "            # initial_len = len(self.data)\n",
    "            # self.data = self.data[self.data['valid_smiles']].reset_index(drop=True)\n",
    "            # print(f\"Filtered out {initial_len - len(self.data)} invalid SMILES.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Data file not found at {data_file_path}\")\n",
    "            self.data = pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing CSV {data_file_path}: {e}\")\n",
    "            self.data = pd.DataFrame()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of samples in the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single item from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing processed spectral features\n",
    "                  and the target fingerprint. Returns None if data is invalid.\n",
    "        \"\"\"\n",
    "        if idx >= len(self.data):\n",
    "             raise IndexError(\"Index out of bounds\")\n",
    "\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # Extract data, ensuring correct types\n",
    "        spec_id = str(row['spec'])\n",
    "        smiles = str(row['smiles'])\n",
    "        raw_spec_json = row['extracted_spectral_info'] \n",
    "\n",
    "        # --- Generate Target Fingerprint ---\n",
    "        target_fp = smiles_to_fingerprint(smiles, self.target_fp_size, self.morgan_radius)\n",
    "        target_fp = torch.tensor(target_fp)\n",
    "     \n",
    "        # --- Process Spectrum ---\n",
    "        spec_features = self.processor.process_raw_spectrum(\n",
    "            raw_spec_json, spec_id=spec_id, train_mode=self.is_train\n",
    "        )\n",
    "        \n",
    "        spec_features = prepare_features(spec_features)\n",
    "        \n",
    "        # --- Combine features and target --- \n",
    "        item = {**spec_features, 'target_fp': target_fp}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742987e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/production_ready_data/train/spectrs/\"\n",
    "TRAIN_CSV = Path(DATA_DIR) / \"MassSpecGym_fixed.csv\" \n",
    "OUTPUT_SIZE = 4096  \n",
    "HIDDEN_SIZE = 256 \n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4    \n",
    "MAGMA_MODULO = 2048 \n",
    "SPECTRA_DROPOUT = 0.1 \n",
    "TOP_LAYERS = 2 \n",
    "USE_MAGMA_AUX_LOSS = True \n",
    "FORM_EMBEDDER = \"float\"\n",
    "MAGMA_FOLDER = '../../data/raw/msg_diffms/magma_outputs/magma_tsv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59efe99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1.0e-6\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "USE_MAGMA_AUX_LOSS = True \n",
    "MAGMA_LOSS_WEIGHT = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d912a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 231104 MAGMA files\n"
     ]
    }
   ],
   "source": [
    "processor_train = SpectrumProcessor(\n",
    "    augment_data=True,\n",
    "    cls_type=\"ms1\",\n",
    "    max_peaks=500,\n",
    "    magma_modulo=MAGMA_MODULO,\n",
    "    magma_aux_loss=USE_MAGMA_AUX_LOSS,\n",
    "    magma_folder=MAGMA_FOLDER if USE_MAGMA_AUX_LOSS else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e603f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 231104 records from ../../data/production_ready_data/train/spectrs/MassSpecGym_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpectraDataset(TRAIN_CSV, processor_train, OUTPUT_SIZE, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae03557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_peaks': tensor(7), 'types': tensor([0, 0, 0, 0, 0, 0, 3]), 'form_vec': tensor([[ 7.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.],\n",
      "        [13., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "          0.,  0.,  0.,  0.],\n",
      "        [13., 13.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
      "          0.,  0.,  0.,  0.],\n",
      "        [14., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  3.,\n",
      "          0.,  0.,  0.,  0.],\n",
      "        [ 7.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  3.,\n",
      "          0.,  0.,  0.,  0.],\n",
      "        [ 6.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,\n",
      "          0.,  0.,  0.,  0.],\n",
      "        [16., 17.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  4.,\n",
      "          0.,  0.,  0.,  0.]]), 'ion_vec': tensor([0, 0, 0, 0, 0, 0, 0]), 'intens': tensor([0.4952, 0.5911, 0.5551, 0.8572, 0.2830, 1.0000, 1.0000]), 'instruments': tensor(0), 'magma_fps': tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]]), 'magma_aux_loss': True, 'target_fp': tensor([0., 0., 0.,  ..., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataset:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024fe251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader created with 3611 batches.\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            collate_fn=spectra_collate_fn,\n",
    "        )\n",
    "print(f\"Train DataLoader created with {len(train_loader)} batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e5b6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectrum-to-molecular-ECHCqm5f-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
